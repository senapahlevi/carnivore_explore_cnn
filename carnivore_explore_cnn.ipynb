{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "carnivore_explore_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0Cyym+Oh2a1cyHL7Z/dvq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdcUkqEJPkfa"
      },
      "source": [
        "These are using dataset from "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYh7LMZ_O61B"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYh-lTKlPJVc"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import sklearn\r\n",
        "import mathimport warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQzqKRuGPcuc"
      },
      "source": [
        "PRETRAINED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcs2fcyuPSAT"
      },
      "source": [
        "import keras\r\n",
        "from keras.applications.inception_v3 import InceptionV3\r\n",
        "from keras.models import Model,load_model\r\n",
        "\r\n",
        "\r\n",
        "conv_base = InceptionV3(weights = 'imagenet',include_top=False,input_shape=(300,300,3))\r\n",
        "\r\n",
        "output = conv_base.layers[-1].output\r\n",
        "output = keras.layers.Flatten()(output)\r\n",
        "model_tl = Model(conv_base.input, output)\r\n",
        "\r\n",
        "model_tl.trainable = False\r\n",
        "for layer in model_tl.layers:\r\n",
        "  layer.trainable = False\r\n",
        "\r\n",
        "layers = [(layer,layer.name,layer.trainable)for layer in\r\n",
        "          model_tl.layers]\r\n",
        "model_layers = pd.DataFrame(layers,columns=['layer Type','Layer Name','Layer Trainable'])\r\n",
        "\r\n",
        "print(model_layers)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oit_RHZhPSDz"
      },
      "source": [
        "#preproses dan data augmentasi\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\r\n",
        "\r\n",
        "test_size = 400\r\n",
        "batch_size =32\r\n",
        "epochs=25\r\n",
        "\r\n",
        "#dataset \r\n",
        "train_path = '/content/drive/MyDrive/TALatihan/carnivores/train'\r\n",
        "test_path = '/content/drive/MyDrive/TALatihan/carnivores/test'\r\n",
        "\r\n",
        "target_size = (300,300) #resize all images to 300x300\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,  \r\n",
        "                                   rotation_range=50,\r\n",
        "                                   width_shift_range=0.2, \r\n",
        "                                   height_shift_range=0.2, \r\n",
        "                                   shear_range=0.2,\r\n",
        "                                   horizontal_flip=True,\r\n",
        "                                   brightness_range = [0.8, 1.2],\r\n",
        "                                   fill_mode='nearest',        \r\n",
        "                                   validation_split=0.2)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "#the list of classes will be automatically inferred from the subdirectory names/stucture under train_dir\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "                  train_path,\r\n",
        "                  target_size=target_size,#  \r\n",
        "                  batch_size=batch_size,\r\n",
        "                  class_mode='categorical',\r\n",
        "                  subset='training')\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "                       train_path,\r\n",
        "                       target_size=target_size,\r\n",
        "                       batch_size=batch_size,\r\n",
        "                       class_mode='categorical',\r\n",
        "                       subset='validation')\r\n",
        "#building model arsitektur\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\r\n",
        "from keras import optimizers\r\n",
        "#building a linear stack of layers with the sequential model\r\n",
        "model = Sequential()\r\n",
        "model.add(model_tl)\r\n",
        "\r\n",
        "#hidden layer\r\n",
        "model.add(Dense(128,activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "#output layer\r\n",
        "model.add(Dense(4,activation='softmax'))\r\n",
        "#resume training abis internet dc/mati lampu\r\n",
        "model.load_weights('/content/drive/MyDrive/TALatihan/CP/epochs:025-val_acc:0.993.hdf5') \r\n",
        "#compiling the sequential model\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\r\n",
        "              metrics=['acc'])\r\n",
        "print(model.summary())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vga4RVhYPSHv"
      },
      "source": [
        "#Saving model checkpoint\r\n",
        "from keras.callbacks import *\r\n",
        "#/content/drive/MyDrive/TALatihan/CP\r\n",
        "\r\n",
        "filepath ='/content/drive/MyDrive/TALatihan/CP/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5'\r\n",
        "checkpoint = ModelCheckpoint(filepath,\r\n",
        "                             monitor='val_acc',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=False,\r\n",
        "                             save_freq='epoch',\r\n",
        "                             mode='max')\r\n",
        "callbacks_list=[checkpoint]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWWAWywAPSL0"
      },
      "source": [
        "\r\n",
        "#model performance\r\n",
        "#model evaluation\r\n",
        "scores_train = model.evaluate(train_generator,verbose=1)\r\n",
        "scores_validation = model.evaluate(validation_generator,verbose=1)\r\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores_train[1]*100))\r\n",
        "print(\"validation akurasi : %.2f%% \"%(scores_validation[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYHT7c-DPSPU"
      },
      "source": [
        "def LearningCurve(history):\r\n",
        "#summarize history for akurasi\r\n",
        "  plt.plot(history.history['acc'])\r\n",
        "  plt.plot(history.history['val_acc'])\r\n",
        "  plt.title('model accurasi')\r\n",
        "  plt.ylabel('accurasi')\r\n",
        "  plt.xlabel('epoch')\r\n",
        "  plt.legend(['train','validation'],loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGqlPdhiPSfp"
      },
      "source": [
        "\r\n",
        "def LearningCurve(history):\r\n",
        "#summarize history for akurasi\r\n",
        "  plt.plot(history.history['acc'])\r\n",
        "  plt.plot(history.history['val_acc'])\r\n",
        "  plt.title('model accurasi')\r\n",
        "  plt.ylabel('accurasi')\r\n",
        "  plt.xlabel('epoch')\r\n",
        "  plt.legend(['train','validation'],loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjkdXhygf6I4"
      },
      "source": [
        "#we take the ceiling because we dont drop the remainder of the batch\r\n",
        "import math\r\n",
        "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))\r\n",
        "test_steps = compute_steps_per_epoch(test_size)\r\n",
        "test_generator = test_datagen.flow_from_directory(\r\n",
        "                 test_path,\r\n",
        "                 target_size=target_size, \r\n",
        "                 batch_size=batch_size,\r\n",
        "                 class_mode=None,\r\n",
        "                 shuffle=False)\r\n",
        "test_generator.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doTEBR0xf6Z-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}